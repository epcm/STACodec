=== Model parameter summary (sorted by size desc) ===
encoder.encoder_transformer.transformer_encoder.embeddings.word_embeddings.weight |    23.44M | train  | (30522, 768)       | torch.float32
encoder.model.12.conv.conv.weight_v                                              |     8.39M | train  | (1024, 512, 16)    | torch.float32
encoder.model.13.lstm.weight_ih_l1                                               |     8.39M | train  | (4096, 2048)       | torch.float32
encoder.model.13.lstm.weight_ih_l1_reverse                                       |     8.39M | train  | (4096, 2048)       | torch.float32
decoder.model.1.lstm.weight_ih_l1                                                |     8.39M | train  | (4096, 2048)       | torch.float32
decoder.model.1.lstm.weight_ih_l1_reverse                                        |     8.39M | train  | (4096, 2048)       | torch.float32
decoder.model.3.convtr.convtr.weight_v                                           |     8.39M | train  | (1024, 512, 16)    | torch.float32
encoder.model.13.lstm.weight_ih_l0                                               |     4.19M | train  | (4096, 1024)       | torch.float32
encoder.model.13.lstm.weight_hh_l0                                               |     4.19M | train  | (4096, 1024)       | torch.float32
encoder.model.13.lstm.weight_ih_l0_reverse                                       |     4.19M | train  | (4096, 1024)       | torch.float32
encoder.model.13.lstm.weight_hh_l0_reverse                                       |     4.19M | train  | (4096, 1024)       | torch.float32
encoder.model.13.lstm.weight_hh_l1                                               |     4.19M | train  | (4096, 1024)       | torch.float32
encoder.model.13.lstm.weight_hh_l1_reverse                                       |     4.19M | train  | (4096, 1024)       | torch.float32
decoder.model.1.lstm.weight_ih_l0                                                |     4.19M | train  | (4096, 1024)       | torch.float32
decoder.model.1.lstm.weight_hh_l0                                                |     4.19M | train  | (4096, 1024)       | torch.float32
decoder.model.1.lstm.weight_ih_l0_reverse                                        |     4.19M | train  | (4096, 1024)       | torch.float32
decoder.model.1.lstm.weight_hh_l0_reverse                                        |     4.19M | train  | (4096, 1024)       | torch.float32
decoder.model.1.lstm.weight_hh_l1                                                |     4.19M | train  | (4096, 1024)       | torch.float32
decoder.model.1.lstm.weight_hh_l1_reverse                                        |     4.19M | train  | (4096, 1024)       | torch.float32
encoder.model.13.projection.weight                                               |     2.10M | train  | (1024, 2048)       | torch.float32
decoder.model.1.projection.weight                                                |     2.10M | train  | (1024, 2048)       | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.0.intermediate.dense.weight |     1.57M | train  | (2048, 768)        | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.0.output.dense.weight |     1.57M | train  | (768, 2048)        | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.1.intermediate.dense.weight |     1.57M | train  | (2048, 768)        | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.1.output.dense.weight |     1.57M | train  | (768, 2048)        | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.2.intermediate.dense.weight |     1.57M | train  | (2048, 768)        | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.2.output.dense.weight |     1.57M | train  | (768, 2048)        | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.3.intermediate.dense.weight |     1.57M | train  | (2048, 768)        | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.3.output.dense.weight |     1.57M | train  | (768, 2048)        | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.4.intermediate.dense.weight |     1.57M | train  | (2048, 768)        | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.4.output.dense.weight |     1.57M | train  | (768, 2048)        | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.5.intermediate.dense.weight |     1.57M | train  | (2048, 768)        | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.5.output.dense.weight |     1.57M | train  | (768, 2048)        | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.6.intermediate.dense.weight |     1.57M | train  | (2048, 768)        | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.6.output.dense.weight |     1.57M | train  | (768, 2048)        | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.7.intermediate.dense.weight |     1.57M | train  | (2048, 768)        | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.7.output.dense.weight |     1.57M | train  | (768, 2048)        | torch.float32
encoder.model.9.conv.conv.weight_v                                               |     1.31M | train  | (512, 256, 10)     | torch.float32
decoder.model.6.convtr.convtr.weight_v                                           |     1.31M | train  | (512, 256, 10)     | torch.float32
encoder.model.15.conv.conv.weight_v                                              |     0.92M | train  | (128, 1024, 7)     | torch.float32
decoder.model.0.conv.conv.weight_v                                               |     0.92M | train  | (1024, 128, 7)     | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.0.attention.self.query.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.0.attention.self.key.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.0.attention.self.value.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.0.attention.output.dense.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.1.attention.self.query.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.1.attention.self.key.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.1.attention.self.value.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.1.attention.output.dense.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.2.attention.self.query.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.2.attention.self.key.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.2.attention.self.value.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.2.attention.output.dense.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.3.attention.self.query.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.3.attention.self.key.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.3.attention.self.value.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.3.attention.output.dense.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.4.attention.self.query.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.4.attention.self.key.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.4.attention.self.value.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.4.attention.output.dense.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.5.attention.self.query.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.5.attention.self.key.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.5.attention.self.value.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.5.attention.output.dense.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.6.attention.self.query.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.6.attention.self.key.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.6.attention.self.value.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.6.attention.output.dense.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.7.attention.self.query.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.7.attention.self.key.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.7.attention.self.value.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.7.attention.output.dense.weight |     0.59M | train  | (768, 768)         | torch.float32
encoder.encoder_transformer.transformer_encoder.pooler.dense.weight              |     0.59M | train  | (768, 768)         | torch.float32
encoder.model.10.block.1.conv.conv.weight_v                                      |     0.39M | train  | (256, 512, 3)      | torch.float32
decoder.model.4.block.1.conv.conv.weight_v                                       |     0.39M | train  | (256, 512, 3)      | torch.float32
encoder.model.6.conv.conv.weight_v                                               |     0.26M | train  | (256, 128, 8)      | torch.float32
decoder.model.9.convtr.convtr.weight_v                                           |     0.26M | train  | (256, 128, 8)      | torch.float32
encoder.model.10.block.3.conv.conv.weight_v                                      |     0.13M | train  | (512, 256, 1)      | torch.float32
decoder.model.4.block.3.conv.conv.weight_v                                       |     0.13M | train  | (512, 256, 1)      | torch.float32
encoder.encoder_transformer.transformer_encoder.embeddings.position_embeddings.weight |     0.12M | train  | (150, 768)         | torch.float32
encoder.model.7.block.1.conv.conv.weight_v                                       |     0.10M | train  | (128, 256, 3)      | torch.float32
encoder.encoder_transformer.in_projection.weight                                 |     0.10M | train  | (768, 128)         | torch.float32
encoder.encoder_transformer.out_projection.weight                                |     0.10M | train  | (128, 768)         | torch.float32
decoder.model.7.block.1.conv.conv.weight_v                                       |     0.10M | train  | (128, 256, 3)      | torch.float32
encoder.model.3.conv.conv.weight_v                                               |     0.03M | train  | (128, 64, 4)       | torch.float32
encoder.model.7.block.3.conv.conv.weight_v                                       |     0.03M | train  | (256, 128, 1)      | torch.float32
decoder.model.7.block.3.conv.conv.weight_v                                       |     0.03M | train  | (256, 128, 1)      | torch.float32
decoder.model.12.convtr.convtr.weight_v                                          |     0.03M | train  | (128, 64, 4)       | torch.float32
encoder.model.4.block.1.conv.conv.weight_v                                       |     0.02M | train  | (64, 128, 3)       | torch.float32
decoder.model.10.block.1.conv.conv.weight_v                                      |     0.02M | train  | (64, 128, 3)       | torch.float32
encoder.model.4.block.3.conv.conv.weight_v                                       |     0.01M | train  | (128, 64, 1)       | torch.float32
decoder.model.10.block.3.conv.conv.weight_v                                      |     0.01M | train  | (128, 64, 1)       | torch.float32
encoder.model.1.block.1.conv.conv.weight_v                                       |     0.01M | train  | (32, 64, 3)        | torch.float32
decoder.model.13.block.1.conv.conv.weight_v                                      |     0.01M | train  | (32, 64, 3)        | torch.float32
encoder.model.13.lstm.bias_ih_l0                                                 |     0.00M | train  | (4096,)            | torch.float32
encoder.model.13.lstm.bias_hh_l0                                                 |     0.00M | train  | (4096,)            | torch.float32
encoder.model.13.lstm.bias_ih_l0_reverse                                         |     0.00M | train  | (4096,)            | torch.float32
encoder.model.13.lstm.bias_hh_l0_reverse                                         |     0.00M | train  | (4096,)            | torch.float32
encoder.model.13.lstm.bias_ih_l1                                                 |     0.00M | train  | (4096,)            | torch.float32
encoder.model.13.lstm.bias_hh_l1                                                 |     0.00M | train  | (4096,)            | torch.float32
encoder.model.13.lstm.bias_ih_l1_reverse                                         |     0.00M | train  | (4096,)            | torch.float32
encoder.model.13.lstm.bias_hh_l1_reverse                                         |     0.00M | train  | (4096,)            | torch.float32
decoder.model.1.lstm.bias_ih_l0                                                  |     0.00M | train  | (4096,)            | torch.float32
decoder.model.1.lstm.bias_hh_l0                                                  |     0.00M | train  | (4096,)            | torch.float32
decoder.model.1.lstm.bias_ih_l0_reverse                                          |     0.00M | train  | (4096,)            | torch.float32
decoder.model.1.lstm.bias_hh_l0_reverse                                          |     0.00M | train  | (4096,)            | torch.float32
decoder.model.1.lstm.bias_ih_l1                                                  |     0.00M | train  | (4096,)            | torch.float32
decoder.model.1.lstm.bias_hh_l1                                                  |     0.00M | train  | (4096,)            | torch.float32
decoder.model.1.lstm.bias_ih_l1_reverse                                          |     0.00M | train  | (4096,)            | torch.float32
decoder.model.1.lstm.bias_hh_l1_reverse                                          |     0.00M | train  | (4096,)            | torch.float32
encoder.model.1.block.3.conv.conv.weight_v                                       |     0.00M | train  | (64, 32, 1)        | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.0.intermediate.dense.bias |     0.00M | train  | (2048,)            | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.1.intermediate.dense.bias |     0.00M | train  | (2048,)            | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.2.intermediate.dense.bias |     0.00M | train  | (2048,)            | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.3.intermediate.dense.bias |     0.00M | train  | (2048,)            | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.4.intermediate.dense.bias |     0.00M | train  | (2048,)            | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.5.intermediate.dense.bias |     0.00M | train  | (2048,)            | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.6.intermediate.dense.bias |     0.00M | train  | (2048,)            | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.7.intermediate.dense.bias |     0.00M | train  | (2048,)            | torch.float32
decoder.model.13.block.3.conv.conv.weight_v                                      |     0.00M | train  | (64, 32, 1)        | torch.float32
encoder.encoder_transformer.transformer_encoder.embeddings.token_type_embeddings.weight |     0.00M | train  | (2, 768)           | torch.float32
encoder.model.12.conv.conv.bias                                                  |     0.00M | train  | (1024,)            | torch.float32
encoder.model.12.conv.conv.weight_g                                              |     0.00M | train  | (1024, 1, 1)       | torch.float32
encoder.model.13.projection.bias                                                 |     0.00M | train  | (1024,)            | torch.float32
decoder.model.0.conv.conv.bias                                                   |     0.00M | train  | (1024,)            | torch.float32
decoder.model.0.conv.conv.weight_g                                               |     0.00M | train  | (1024, 1, 1)       | torch.float32
decoder.model.1.projection.bias                                                  |     0.00M | train  | (1024,)            | torch.float32
decoder.model.3.convtr.convtr.weight_g                                           |     0.00M | train  | (1024, 1, 1)       | torch.float32
encoder.encoder_transformer.in_projection.bias                                   |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.embeddings.LayerNorm.weight      |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.embeddings.LayerNorm.bias        |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.0.attention.self.query.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.0.attention.self.key.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.0.attention.self.value.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.0.attention.output.dense.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.0.attention.output.LayerNorm.weight |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.0.attention.output.LayerNorm.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.0.output.dense.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.0.output.LayerNorm.weight |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.0.output.LayerNorm.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.1.attention.self.query.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.1.attention.self.key.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.1.attention.self.value.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.1.attention.output.dense.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.1.attention.output.LayerNorm.weight |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.1.attention.output.LayerNorm.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.1.output.dense.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.1.output.LayerNorm.weight |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.1.output.LayerNorm.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.2.attention.self.query.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.2.attention.self.key.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.2.attention.self.value.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.2.attention.output.dense.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.2.attention.output.LayerNorm.weight |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.2.attention.output.LayerNorm.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.2.output.dense.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.2.output.LayerNorm.weight |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.2.output.LayerNorm.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.3.attention.self.query.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.3.attention.self.key.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.3.attention.self.value.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.3.attention.output.dense.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.3.attention.output.LayerNorm.weight |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.3.attention.output.LayerNorm.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.3.output.dense.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.3.output.LayerNorm.weight |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.3.output.LayerNorm.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.4.attention.self.query.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.4.attention.self.key.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.4.attention.self.value.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.4.attention.output.dense.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.4.attention.output.LayerNorm.weight |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.4.attention.output.LayerNorm.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.4.output.dense.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.4.output.LayerNorm.weight |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.4.output.LayerNorm.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.5.attention.self.query.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.5.attention.self.key.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.5.attention.self.value.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.5.attention.output.dense.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.5.attention.output.LayerNorm.weight |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.5.attention.output.LayerNorm.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.5.output.dense.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.5.output.LayerNorm.weight |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.5.output.LayerNorm.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.6.attention.self.query.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.6.attention.self.key.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.6.attention.self.value.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.6.attention.output.dense.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.6.attention.output.LayerNorm.weight |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.6.attention.output.LayerNorm.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.6.output.dense.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.6.output.LayerNorm.weight |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.6.output.LayerNorm.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.7.attention.self.query.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.7.attention.self.key.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.7.attention.self.value.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.7.attention.output.dense.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.7.attention.output.LayerNorm.weight |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.7.attention.output.LayerNorm.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.7.output.dense.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.7.output.LayerNorm.weight |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.encoder.layer.7.output.LayerNorm.bias |     0.00M | train  | (768,)             | torch.float32
encoder.encoder_transformer.transformer_encoder.pooler.dense.bias                |     0.00M | train  | (768,)             | torch.float32
encoder.model.9.conv.conv.bias                                                   |     0.00M | train  | (512,)             | torch.float32
encoder.model.9.conv.conv.weight_g                                               |     0.00M | train  | (512, 1, 1)        | torch.float32
encoder.model.10.block.3.conv.conv.bias                                          |     0.00M | train  | (512,)             | torch.float32
encoder.model.10.block.3.conv.conv.weight_g                                      |     0.00M | train  | (512, 1, 1)        | torch.float32
decoder.model.3.convtr.convtr.bias                                               |     0.00M | train  | (512,)             | torch.float32
decoder.model.4.block.3.conv.conv.bias                                           |     0.00M | train  | (512,)             | torch.float32
decoder.model.4.block.3.conv.conv.weight_g                                       |     0.00M | train  | (512, 1, 1)        | torch.float32
decoder.model.6.convtr.convtr.weight_g                                           |     0.00M | train  | (512, 1, 1)        | torch.float32
encoder.model.0.conv.conv.weight_v                                               |     0.00M | train  | (64, 1, 7)         | torch.float32
decoder.model.15.conv.conv.weight_v                                              |     0.00M | train  | (1, 64, 7)         | torch.float32
encoder.model.6.conv.conv.bias                                                   |     0.00M | train  | (256,)             | torch.float32
encoder.model.6.conv.conv.weight_g                                               |     0.00M | train  | (256, 1, 1)        | torch.float32
encoder.model.7.block.3.conv.conv.bias                                           |     0.00M | train  | (256,)             | torch.float32
encoder.model.7.block.3.conv.conv.weight_g                                       |     0.00M | train  | (256, 1, 1)        | torch.float32
encoder.model.10.block.1.conv.conv.bias                                          |     0.00M | train  | (256,)             | torch.float32
encoder.model.10.block.1.conv.conv.weight_g                                      |     0.00M | train  | (256, 1, 1)        | torch.float32
decoder.model.4.block.1.conv.conv.bias                                           |     0.00M | train  | (256,)             | torch.float32
decoder.model.4.block.1.conv.conv.weight_g                                       |     0.00M | train  | (256, 1, 1)        | torch.float32
decoder.model.6.convtr.convtr.bias                                               |     0.00M | train  | (256,)             | torch.float32
decoder.model.7.block.3.conv.conv.bias                                           |     0.00M | train  | (256,)             | torch.float32
decoder.model.7.block.3.conv.conv.weight_g                                       |     0.00M | train  | (256, 1, 1)        | torch.float32
decoder.model.9.convtr.convtr.weight_g                                           |     0.00M | train  | (256, 1, 1)        | torch.float32
encoder.model.3.conv.conv.bias                                                   |     0.00M | train  | (128,)             | torch.float32
encoder.model.3.conv.conv.weight_g                                               |     0.00M | train  | (128, 1, 1)        | torch.float32
encoder.model.4.block.3.conv.conv.bias                                           |     0.00M | train  | (128,)             | torch.float32
encoder.model.4.block.3.conv.conv.weight_g                                       |     0.00M | train  | (128, 1, 1)        | torch.float32
encoder.model.7.block.1.conv.conv.bias                                           |     0.00M | train  | (128,)             | torch.float32
encoder.model.7.block.1.conv.conv.weight_g                                       |     0.00M | train  | (128, 1, 1)        | torch.float32
encoder.model.15.conv.conv.bias                                                  |     0.00M | train  | (128,)             | torch.float32
encoder.model.15.conv.conv.weight_g                                              |     0.00M | train  | (128, 1, 1)        | torch.float32
encoder.encoder_transformer.out_projection.bias                                  |     0.00M | train  | (128,)             | torch.float32
decoder.model.7.block.1.conv.conv.bias                                           |     0.00M | train  | (128,)             | torch.float32
decoder.model.7.block.1.conv.conv.weight_g                                       |     0.00M | train  | (128, 1, 1)        | torch.float32
decoder.model.9.convtr.convtr.bias                                               |     0.00M | train  | (128,)             | torch.float32
decoder.model.10.block.3.conv.conv.bias                                          |     0.00M | train  | (128,)             | torch.float32
decoder.model.10.block.3.conv.conv.weight_g                                      |     0.00M | train  | (128, 1, 1)        | torch.float32
decoder.model.12.convtr.convtr.weight_g                                          |     0.00M | train  | (128, 1, 1)        | torch.float32
encoder.model.0.conv.conv.bias                                                   |     0.00M | train  | (64,)              | torch.float32
encoder.model.0.conv.conv.weight_g                                               |     0.00M | train  | (64, 1, 1)         | torch.float32
encoder.model.1.block.3.conv.conv.bias                                           |     0.00M | train  | (64,)              | torch.float32
encoder.model.1.block.3.conv.conv.weight_g                                       |     0.00M | train  | (64, 1, 1)         | torch.float32
encoder.model.4.block.1.conv.conv.bias                                           |     0.00M | train  | (64,)              | torch.float32
encoder.model.4.block.1.conv.conv.weight_g                                       |     0.00M | train  | (64, 1, 1)         | torch.float32
decoder.model.10.block.1.conv.conv.bias                                          |     0.00M | train  | (64,)              | torch.float32
decoder.model.10.block.1.conv.conv.weight_g                                      |     0.00M | train  | (64, 1, 1)         | torch.float32
decoder.model.12.convtr.convtr.bias                                              |     0.00M | train  | (64,)              | torch.float32
decoder.model.13.block.3.conv.conv.bias                                          |     0.00M | train  | (64,)              | torch.float32
decoder.model.13.block.3.conv.conv.weight_g                                      |     0.00M | train  | (64, 1, 1)         | torch.float32
encoder.model.1.block.1.conv.conv.bias                                           |     0.00M | train  | (32,)              | torch.float32
encoder.model.1.block.1.conv.conv.weight_g                                       |     0.00M | train  | (32, 1, 1)         | torch.float32
decoder.model.13.block.1.conv.conv.bias                                          |     0.00M | train  | (32,)              | torch.float32
decoder.model.13.block.1.conv.conv.weight_g                                      |     0.00M | train  | (32, 1, 1)         | torch.float32
decoder.model.15.conv.conv.bias                                                  |     0.00M | train  | (1,)               | torch.float32
decoder.model.15.conv.conv.weight_g                                              |     0.00M | train  | (1, 1, 1)          | torch.float32

Total params:     179.84M
Trainable params: 179.84M
Frozen params:    0.00M
